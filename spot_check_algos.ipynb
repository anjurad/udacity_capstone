{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from azureml.core.workspace import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ws.datasets[\"job-leaver-aug-small\"].to_pandas_dataframe()\n",
    "# change objects to category to impute\n",
    "for col in dataset.select_dtypes(object):\n",
    "    dataset[col] = dataset[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['enrollee_id', 'city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['target'], axis=1)\n",
    "y = np.array(dataset['target'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Algorithms\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'f1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_max_iter = 100\n",
    "args_min_features = 3\n",
    "args_C = 0.25\n",
    "\n",
    "# Setting up the sklean pipeline\n",
    "\n",
    "# RFE\n",
    "svc = SVC(kernel=\"linear\")\n",
    "min_features_to_select = args_min_features\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "# model\n",
    "logreg = LogisticRegression(\n",
    "    C=args_C,\n",
    "    max_iter=args_max_iter,\n",
    "    class_weight='balanced',\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,)\n",
    "\n",
    "# transformer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=\"category\"))\n",
    "])\n",
    "\n",
    "# pipeline\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('rfecv', rfecv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "pipelines = []\n",
    "pipelines.append(('LR', Pipeline([('prep', preprocessor),('LR', logreg)])))\n",
    "pipelines.append(('LDA', Pipeline([('prep', preprocessor),('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('KNN', Pipeline([('prep', preprocessor),('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('CART', Pipeline([('prep', preprocessor),('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('NB', Pipeline([('prep', preprocessor),('NB', GaussianNB())])))\n",
    "pipelines.append(('SVM', Pipeline([('prep', preprocessor),('SVM', SVC())])))\n",
    "\n",
    "#ensembles\n",
    "pipelines.append(('AdaBoost', Pipeline([('prep', preprocessor),('SVM', AdaBoostClassifier())])))\n",
    "pipelines.append(('GBM', Pipeline([('prep', preprocessor),('SVM', GradientBoostingClassifier())])))\n",
    "pipelines.append(('RF', Pipeline([('prep', preprocessor),('SVM', RandomForestClassifier())])))\n",
    "pipelines.append(('ET', Pipeline([('prep', preprocessor),('SVM', ExtraTreesClassifier())])))\n",
    "\n",
    "metrics = []\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    for metric in [balanced_accuracy_score, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score]:\n",
    "        metrics.append([name, metric.__name__, np.float(metric(y_test, y_pred))])\n",
    "    \n",
    "    print(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = pyplot.figure(figsize=(15,7.5))\n",
    "fig.suptitle('Scaled Algorithm Comparison using F1 score')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the compared metrics\n",
    "pd.DataFrame(data=metrics).pivot(index=1, columns=0, values=2).apply(lambda x: np.round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the different metrics meant for multi-class are performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('prep', preprocessor),('LR', logreg)])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_score\n",
      "default: 0.7195121951219512\n",
      "macro: 0.685444170955471\n",
      "micro: 0.67\n",
      "weighted: 0.67\n",
      "\n",
      "Confusion Matrix:\n",
      "[[142  76]\n",
      " [ 23  59]]\n"
     ]
    }
   ],
   "source": [
    "# This cell just to check the different versions of any metric, ito macro, micro and weighted\n",
    "\"Details can be found here:  https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#classification-metrics\"\n",
    "print(\"recall_score\")\n",
    "print(f\"default: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"macro: {recall_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"micro: {recall_score(y_test, y_pred, average='micro')}\")\n",
    "print(f\"weighted: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
